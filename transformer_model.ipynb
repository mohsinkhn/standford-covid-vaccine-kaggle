{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import math\n",
    "\n",
    "from catalyst import dl\n",
    "from catalyst.dl import utils\n",
    "from catalyst.core.callbacks.scheduler import SchedulerCallback\n",
    "from catalyst.contrib.dl.callbacks.neptune_logger import NeptuneLogger\n",
    "from catalyst.contrib.nn.schedulers.onecycle import OneCycleLRWithWarmup\n",
    "from catalyst.contrib.nn.optimizers.ralamb import Ralamb\n",
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from torchcontrib.optim import SWA\n",
    "\n",
    "from constants import FilePaths, TGT_COLS\n",
    "from datasets import RNAAugData, RNAAugDatav2\n",
    "from modellib import RNNmodels\n",
    "from modellib.RNNmodels import ParamModel, Conv2dBn, Conv1dBn, onehot\n",
    "from modellib.transformermodels import Conv2D1x1, TransformerCustomEncoder, PositionalEncoding\n",
    "from nn_trainer import MCRMSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = 8\n",
    "NUM_FOLDS = 5\n",
    "\n",
    "BATCH_SIZE = 12\n",
    "FP = FilePaths(\"data\")\n",
    "train = pd.read_json(FP.train_json, lines=True)\n",
    "cvlist = list(\n",
    "    StratifiedKFold(NUM_FOLDS, shuffle=True, random_state=1234786).split(\n",
    "        train, train[\"SN_filter\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "device = utils.get_device()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'num_epochs': 150,\n",
       " 'num_folds': 5,\n",
       " 'seed': 1234786,\n",
       " 'seq_emb_dim': 64,\n",
       " 'struct_emb_dim': 64,\n",
       " 'pl_emb_dim': 64,\n",
       " 'combined_emb_dim': 150,\n",
       " 'gru_dim': 256,\n",
       " 'rnn_type': 'lstm',\n",
       " 'gru_layers': 3,\n",
       " 'bidirectional': True,\n",
       " 'dropout_prob': 0.75,\n",
       " 'spatial_dropout': 0.5,\n",
       " 'target_dim': 5,\n",
       " 'num_features': 3,\n",
       " 'max_seq_pred': 68,\n",
       " 'lr': 0.0005,\n",
       " 'wd': 1e-08,\n",
       " 'filter_sn': True,\n",
       " 'add_error_noise': True,\n",
       " 'model_name': 'RCNNGRUModelv6',\n",
       " 'conv_channels': [128, 128, 256, 256, 256],\n",
       " 'bpp_conv_channels': [128, 128, 256, 256, 256],\n",
       " 'kernel_size': 5,\n",
       " 'stride': 1,\n",
       " 'add_bpp': True,\n",
       " 'use_one_hot': False,\n",
       " 'sig_factor': 1.0,\n",
       " 'run_on_single': False,\n",
       " 'optimizer': 'adam',\n",
       " 'scheduler': 'reducelrplateau',\n",
       " 'conv_drop': 0.75,\n",
       " 'use_codon': False,\n",
       " 'prob_thresh': 0.0,\n",
       " 'signal_to_noise': 1.0,\n",
       " 'use_augment': True,\n",
       " 'loss_func': 'mcrmse'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams = json.load(open(\"hparams.json\"))\n",
    "hparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fold_num in [0]:\n",
    "    tr_idx, val_idx = cvlist[fold_num]\n",
    "    tr, vl = train.iloc[tr_idx], train.iloc[val_idx]\n",
    "    if hparams.get(\"filter_sn\"):\n",
    "        tr = tr.loc[tr[\"signal_to_noise\"] > hparams.get(\"signal_to_noise\", 1.0)]\n",
    "        vl = vl.loc[vl[\"signal_to_noise\"] > hparams.get(\"signal_to_noise\", 1.0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_fold(tr, vl, hparams, logger, logdir, device, embeddings):\n",
    "    tr_ds = RNAAugDatav2(\n",
    "        tr,\n",
    "        targets=TGT_COLS,\n",
    "        augment_strucures= False,  # hparams.get(\"use_augment\", True),\n",
    "        aug_data_sources=[\n",
    "                          \"data/augmented_data_public/aug_data5.csv\",\n",
    "                          \"data/augmented_data_public/aug_data5_10.csv\",\n",
    "                          \"data/vienna_7_mec.csv\", \n",
    "                          \"data/vienna_17_mec.csv\", \n",
    "                          \"data/vienna_27_mec.csv\",\n",
    "                          \"data/vienna_47_mec.csv\",\n",
    "                          \"data/vienna_57_mec.csv\",\n",
    "                          \"data/vienna_67_mec.csv\"\n",
    "                           ],\n",
    "        target_aug=False,\n",
    "        bpps_path=\"data/bpps\",\n",
    "    )\n",
    "    vl_ds = RNAAugDatav2(vl, targets=TGT_COLS, bpps_path=\"data/bpps\")\n",
    "\n",
    "    tr_dl = DataLoader(tr_ds, shuffle=True, drop_last=True, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,)\n",
    "    vl_dl = DataLoader(vl_ds, shuffle=False, drop_last=False, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS,)\n",
    "\n",
    "    model = RNATransformer(hparams, embeddings.to(device))\n",
    "    if hparams.get(\"optimizer\", \"adam\") == \"adam\":\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=hparams.get(\"lr\", 1e-3), weight_decay=hparams.get(\"wd\", 0),\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr=hparams.get(\"lr\", 1e-3),\n",
    "            weight_decay=hparams.get(\"wd\", 0),\n",
    "            momentum=0.9,\n",
    "            nesterov=True,\n",
    "        )\n",
    "    if hparams.get(\"scheduler\", \"reducelrplateau\") == \"reducelrplateau\":\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, factor=0.5, min_lr=2e-4)\n",
    "    if hparams.get(\"scheduler\", \"reducelrplateau\") == \"one_cycle\":\n",
    "        total_steps = hparams.get(\"num_epochs\") * (len(tr) // hparams.get(\"batch_size\"))\n",
    "        max_lr = hparams.get(\"lr\", 1e-3)\n",
    "        scheduler = OneCycleLRWithWarmup(\n",
    "            optimizer, num_steps=total_steps, lr_range=(max_lr, max_lr / 10, max_lr / 100), warmup_fraction=0.5,\n",
    "        )\n",
    "    \n",
    "    if hparams.get(\"loss_func\", \"mcrmse\") == \"mcrmse\":\n",
    "        criterion = MCRMSE()\n",
    "    elif hparams.get(\"loss_func\") == \"mcmsre\":\n",
    "        criterion = MCMSRE()\n",
    "    runner = dl.SupervisedRunner(device=device)\n",
    "    runner.train(\n",
    "        loaders={\"train\": tr_dl, \"valid\": vl_dl},\n",
    "        model=model,\n",
    "        criterion=criterion,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=hparams.get(\"num_epochs\", 10),\n",
    "        logdir=logdir,\n",
    "        verbose=0,\n",
    "        # callbacks=[logger, SchedulerCallback(mode=\"epoch\")],\n",
    "        load_best_on_end=True,\n",
    "        # resume=\"logs/filter__cnnlstm__posembv5/fold_0/checkpoints/best_full.pth\"\n",
    "    )\n",
    "    return model, tr_dl, vl_dl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('logs/transformer__test/fold_0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams[\"loss_func\"] = \"mcrmse\"\n",
    "hparams[\"batch_size\"] = BATCH_SIZE\n",
    "hparams[\"num_epochs\"] = 300\n",
    "hparams[\"lr\"] = 5e-4\n",
    "hparams[\"wd\"] = 1e-5\n",
    "tags = [\"transformer\", \"test\"]\n",
    "exp_dir = Path(\"./logs\") / \"__\".join(tags)\n",
    "exp_dir.mkdir(exist_ok=True, parents=True)\n",
    "logdir = exp_dir / f\"fold_{fold_num}\"\n",
    "logdir.mkdir(exist_ok=True)\n",
    "\n",
    "# neptune_logger = NeptuneLogger(\n",
    "#     api_token=os.environ[\"NEPTUNE_API_TOKEN\"],\n",
    "#     project_name=\"tezdhar/Covid-RNA-degradation\",\n",
    "#     name=\"covid_rna_degradation\",\n",
    "#     params=hparams,\n",
    "#     tags=tags + [f\"fold_{fold_num}\"],\n",
    "#     upload_source_files=[\"*.py\", \"modellib/*.py\"],\n",
    "# )\n",
    "logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNATransformer(ParamModel):\n",
    "    def __init__(self, hparams, embeddings):\n",
    "        super().__init__(hparams=hparams)\n",
    "        emb_dim = 32\n",
    "        self.sequence_embedding = nn.Embedding(self.num_seq_tokens, emb_dim) # nn.Embedding.from_pretrained(embeddings, freeze=False) \n",
    "        # self.sequence_embedding.weight = nn.Parameter(embeddings/8)\n",
    "\n",
    "        self.structure_embedding = nn.Embedding(self.num_struct_tokens, emb_dim)\n",
    "        self.predicted_loop_embedding = nn.Embedding(self.num_pl_tokens, emb_dim)\n",
    "\n",
    "        # xseq = onehot(xinputs[\"sequence\"], self.num_seq_tokens)\n",
    "        # xstruct = onehot(xinputs[\"structure\"], self.num_struct_tokens)\n",
    "        # xpl = onehot(xinputs[\"predicted_loop_type\"], self.num_pl_tokens)\n",
    "        # xpairseq = onehot(xinputs[\"pair_sequence\"], self.num_seq_tokens)\n",
    "\n",
    "        value_conv_channels1 = [emb_dim*2] + [64, 64, 64] \n",
    "        self.value_conv1 = nn.Sequential(*[Conv1dBn(value_conv_channels1[i], value_conv_channels1[i+1], drop=0.1)\n",
    "                                       for i in range(len(value_conv_channels1)-1)])\n",
    "        value_conv_channels2 = [emb_dim*2] + [64, 64, 64] \n",
    "        self.value_conv2 = nn.Sequential(*[Conv1dBn(value_conv_channels2[i], value_conv_channels2[i+1], drop=0.1)\n",
    "                                       for i in range(len(value_conv_channels2)-1)])\n",
    "        #self.value_conv3 = nn.Sequential(*[Conv1dBn(value_conv_channels[i], value_conv_channels[i+1], drop=0.2)\n",
    "        #                               for i in range(len(value_conv_channels)-1)])\n",
    "        self.cont_conv = Conv1dBn(4, 32)\n",
    "        self.pos1 = PositionalEncoding(emb_dim)\n",
    "        self.pos2 = PositionalEncoding(emb_dim)\n",
    "\n",
    "        # self.fc11 = nn.Linear\n",
    "        bpp_input_channels = 15\n",
    "        bpp_conv_channels = [256, 8]\n",
    "        d_input = value_conv_channels1[-1] + value_conv_channels2[-1] + emb_dim * 2\n",
    "        # bpps_single_head1 = SingleHeadStaticAttn(d_input, 512, 0.5)\n",
    "        # self.bpps_multihead1 = MultiHeadStaticAttn(bpps_single_head1, bpp_input_channels, bpp_conv_channels, 0.5)\n",
    "        self.bpp_transformer = TransformerCustomEncoder(1, d_input, 512, bpp_input_channels, bpp_conv_channels, 0.1, 0.1)\n",
    "        encoder = nn.TransformerEncoderLayer(d_input, 8, 512, activation='gelu', dropout=0.1)\n",
    "        self.transformer = nn.TransformerEncoder(encoder, 3)\n",
    "        self.drop = nn.Dropout(0.1)\n",
    "        self.fc1 = nn.Linear(d_input * 2, 512)\n",
    "        self.fc2 = nn.Linear(512, 5)\n",
    "\n",
    "\n",
    "    def forward(self, xinputs):\n",
    "        # transformer layer does weighted sum of all vectors\n",
    "        # the weight score is Q * K.T, which in our case is similar to bpp matrix\n",
    "        # the original bpp_matrix has very low probilities with non-normal distribution\n",
    "        # so we use conv layers to map BPP matric to attention map, (bathc_size, seq_len, heads)\n",
    "        # the remains value layer V --> we do 1D conv for that\n",
    "\n",
    "        xseq = self.sequence_embedding(xinputs[\"sequence\"])\n",
    "        xstruct = self.structure_embedding(xinputs[\"structure\"])\n",
    "        xpl = self.predicted_loop_embedding(xinputs[\"predicted_loop_type\"])\n",
    "        xpairseq = self.sequence_embedding(xinputs[\"pair_sequence\"])\n",
    "        \n",
    "        xseq = self.value_conv1(torch.cat([xseq, xpairseq], -1).permute(0, 2, 1).contiguous())\n",
    "        xstruct = self.value_conv2(torch.cat([xstruct, xpl], -1).permute(0, 2, 1).contiguous())\n",
    "        # xpl = self.value_conv3(xpl.permute(0, 2, 1).contiguous())\n",
    "        # xpairseq = self.value_conv1(xseq.permute(0, 2, 1).contiguous())\n",
    "\n",
    "        # V = self.value_conv(xseqs.permute(0, 2, 1).contiguous())  # batch_size, key_dim, seq_length\n",
    "        xseq = self.pos1(xseq.permute(0, 2, 1).contiguous()).permute(0, 2, 1).contiguous()\n",
    "        xstruct = self.pos2(xstruct.permute(0, 2, 1).contiguous()).permute(0, 2, 1).contiguous()\n",
    "        \n",
    "        V = torch.cat([xseq, xstruct], 1)\n",
    "        \n",
    "        # print(xpos.shape)\n",
    "        xbpps_inp = xinputs[\"bpps\"].permute(0, 3, 1, 2).contiguous()\n",
    "    \n",
    "        #V = self.pos(V.permute(0, 2, 1).contiguous()).permute(0, 2, 1).contiguous()\n",
    "        # x_attn = self.bpps_multihead1(V, xbpps_inp)\n",
    "        x_attn = self.bpp_transformer(V, xbpps_inp)\n",
    "        x_attn = x_attn.permute(0,2,1).contiguous()\n",
    "        x2 = self.transformer(V.permute(0,2,1).contiguous())\n",
    "        x_attn = torch.cat([x_attn, x2], dim=-1)\n",
    "        bpps_mean_mean = xbpps_inp.mean(dim=(1, 2)).unsqueeze(2)\n",
    "        bpps_max_mean = xbpps_inp.max(dim=2).values.mean(dim=1).unsqueeze(2)\n",
    "        bpps_max_max = xbpps_inp.max(dim=2).values.max(dim=1).values.unsqueeze(2)\n",
    "        bpps_mean_std = torch.clamp(xbpps_inp.mean(dim=2).std(dim=1).unsqueeze(2), -2, 2)\n",
    "        # cont_emb = torch.cat([bpps_mean_mean, bpps_max_mean, bpps_max_max, bpps_mean_std], -1)\n",
    "        # cont_emb = self.cont_conv(cont_emb.permute(0, 2, 1).contiguous()).permute(0, 2, 1).contiguous()\n",
    "        # x_attn = torch.cat([x_attn, cont_emb], -1)\n",
    "        x_attn = x_attn[:, :self.max_seq_pred, :]\n",
    "        x_attn = self.drop(x_attn)\n",
    "        return self.fc2(self.drop(self.fc1(x_attn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-d1df1a6c6286>:2: DeprecationWarning:\n",
      "\n",
      "Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w2v_model = KeyedVectors.load(\"data/w2v_seq_6gram.vectors\")\n",
    "embeddings = [np.zeros(shape=(32,))] + [w2v_model.wv[str(i)] for i in range(len(w2v_model.vocab))]\n",
    "embeddings = np.vstack(embeddings).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsin_okcredit_in/projects/standford-covid-vaccine-kaggle/datasets.py:181: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-09-27 10:32:51,053] \n",
      "1/300 * Epoch 1 (_base): lr=0.0005 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): loss=0.3877\n",
      "1/300 * Epoch 1 (valid): loss=0.3153\n",
      "[2020-09-27 10:32:51,053] \n",
      "1/300 * Epoch 1 (_base): lr=0.0005 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): loss=0.3877\n",
      "1/300 * Epoch 1 (valid): loss=0.3153\n",
      "[2020-09-27 10:32:51,053] \n",
      "1/300 * Epoch 1 (_base): lr=0.0005 | momentum=0.9000\n",
      "1/300 * Epoch 1 (train): loss=0.3877\n",
      "1/300 * Epoch 1 (valid): loss=0.3153\n",
      "[2020-09-27 10:33:18,203] \n",
      "2/300 * Epoch 2 (_base): lr=0.0005 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): loss=0.3239\n",
      "2/300 * Epoch 2 (valid): loss=0.2954\n",
      "[2020-09-27 10:33:18,203] \n",
      "2/300 * Epoch 2 (_base): lr=0.0005 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): loss=0.3239\n",
      "2/300 * Epoch 2 (valid): loss=0.2954\n",
      "[2020-09-27 10:33:18,203] \n",
      "2/300 * Epoch 2 (_base): lr=0.0005 | momentum=0.9000\n",
      "2/300 * Epoch 2 (train): loss=0.3239\n",
      "2/300 * Epoch 2 (valid): loss=0.2954\n",
      "[2020-09-27 10:33:45,572] \n",
      "3/300 * Epoch 3 (_base): lr=0.0005 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): loss=0.3059\n",
      "3/300 * Epoch 3 (valid): loss=0.2934\n",
      "[2020-09-27 10:33:45,572] \n",
      "3/300 * Epoch 3 (_base): lr=0.0005 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): loss=0.3059\n",
      "3/300 * Epoch 3 (valid): loss=0.2934\n",
      "[2020-09-27 10:33:45,572] \n",
      "3/300 * Epoch 3 (_base): lr=0.0005 | momentum=0.9000\n",
      "3/300 * Epoch 3 (train): loss=0.3059\n",
      "3/300 * Epoch 3 (valid): loss=0.2934\n",
      "[2020-09-27 10:34:11,620] \n",
      "4/300 * Epoch 4 (_base): lr=0.0005 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): loss=0.2989\n",
      "4/300 * Epoch 4 (valid): loss=0.2826\n",
      "[2020-09-27 10:34:11,620] \n",
      "4/300 * Epoch 4 (_base): lr=0.0005 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): loss=0.2989\n",
      "4/300 * Epoch 4 (valid): loss=0.2826\n",
      "[2020-09-27 10:34:11,620] \n",
      "4/300 * Epoch 4 (_base): lr=0.0005 | momentum=0.9000\n",
      "4/300 * Epoch 4 (train): loss=0.2989\n",
      "4/300 * Epoch 4 (valid): loss=0.2826\n",
      "[2020-09-27 10:34:38,519] \n",
      "5/300 * Epoch 5 (_base): lr=0.0005 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): loss=0.2914\n",
      "5/300 * Epoch 5 (valid): loss=0.2784\n",
      "[2020-09-27 10:34:38,519] \n",
      "5/300 * Epoch 5 (_base): lr=0.0005 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): loss=0.2914\n",
      "5/300 * Epoch 5 (valid): loss=0.2784\n",
      "[2020-09-27 10:34:38,519] \n",
      "5/300 * Epoch 5 (_base): lr=0.0005 | momentum=0.9000\n",
      "5/300 * Epoch 5 (train): loss=0.2914\n",
      "5/300 * Epoch 5 (valid): loss=0.2784\n",
      "[2020-09-27 10:35:04,377] \n",
      "6/300 * Epoch 6 (_base): lr=0.0005 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): loss=0.2824\n",
      "6/300 * Epoch 6 (valid): loss=0.2742\n",
      "[2020-09-27 10:35:04,377] \n",
      "6/300 * Epoch 6 (_base): lr=0.0005 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): loss=0.2824\n",
      "6/300 * Epoch 6 (valid): loss=0.2742\n",
      "[2020-09-27 10:35:04,377] \n",
      "6/300 * Epoch 6 (_base): lr=0.0005 | momentum=0.9000\n",
      "6/300 * Epoch 6 (train): loss=0.2824\n",
      "6/300 * Epoch 6 (valid): loss=0.2742\n",
      "[2020-09-27 10:35:31,947] \n",
      "7/300 * Epoch 7 (_base): lr=0.0005 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): loss=0.2788\n",
      "7/300 * Epoch 7 (valid): loss=0.2695\n",
      "[2020-09-27 10:35:31,947] \n",
      "7/300 * Epoch 7 (_base): lr=0.0005 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): loss=0.2788\n",
      "7/300 * Epoch 7 (valid): loss=0.2695\n",
      "[2020-09-27 10:35:31,947] \n",
      "7/300 * Epoch 7 (_base): lr=0.0005 | momentum=0.9000\n",
      "7/300 * Epoch 7 (train): loss=0.2788\n",
      "7/300 * Epoch 7 (valid): loss=0.2695\n",
      "[2020-09-27 10:35:57,558] \n",
      "8/300 * Epoch 8 (_base): lr=0.0005 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): loss=0.2745\n",
      "8/300 * Epoch 8 (valid): loss=0.2746\n",
      "[2020-09-27 10:35:57,558] \n",
      "8/300 * Epoch 8 (_base): lr=0.0005 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): loss=0.2745\n",
      "8/300 * Epoch 8 (valid): loss=0.2746\n",
      "[2020-09-27 10:35:57,558] \n",
      "8/300 * Epoch 8 (_base): lr=0.0005 | momentum=0.9000\n",
      "8/300 * Epoch 8 (train): loss=0.2745\n",
      "8/300 * Epoch 8 (valid): loss=0.2746\n",
      "[2020-09-27 10:36:23,258] \n",
      "9/300 * Epoch 9 (_base): lr=0.0005 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): loss=0.2712\n",
      "9/300 * Epoch 9 (valid): loss=0.2647\n",
      "[2020-09-27 10:36:23,258] \n",
      "9/300 * Epoch 9 (_base): lr=0.0005 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): loss=0.2712\n",
      "9/300 * Epoch 9 (valid): loss=0.2647\n",
      "[2020-09-27 10:36:23,258] \n",
      "9/300 * Epoch 9 (_base): lr=0.0005 | momentum=0.9000\n",
      "9/300 * Epoch 9 (train): loss=0.2712\n",
      "9/300 * Epoch 9 (valid): loss=0.2647\n",
      "[2020-09-27 10:36:51,261] \n",
      "10/300 * Epoch 10 (_base): lr=0.0005 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): loss=0.2680\n",
      "10/300 * Epoch 10 (valid): loss=0.2673\n",
      "[2020-09-27 10:36:51,261] \n",
      "10/300 * Epoch 10 (_base): lr=0.0005 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): loss=0.2680\n",
      "10/300 * Epoch 10 (valid): loss=0.2673\n",
      "[2020-09-27 10:36:51,261] \n",
      "10/300 * Epoch 10 (_base): lr=0.0005 | momentum=0.9000\n",
      "10/300 * Epoch 10 (train): loss=0.2680\n",
      "10/300 * Epoch 10 (valid): loss=0.2673\n",
      "[2020-09-27 10:37:17,807] \n",
      "11/300 * Epoch 11 (_base): lr=0.0005 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): loss=0.2672\n",
      "11/300 * Epoch 11 (valid): loss=0.2635\n",
      "[2020-09-27 10:37:17,807] \n",
      "11/300 * Epoch 11 (_base): lr=0.0005 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): loss=0.2672\n",
      "11/300 * Epoch 11 (valid): loss=0.2635\n",
      "[2020-09-27 10:37:17,807] \n",
      "11/300 * Epoch 11 (_base): lr=0.0005 | momentum=0.9000\n",
      "11/300 * Epoch 11 (train): loss=0.2672\n",
      "11/300 * Epoch 11 (valid): loss=0.2635\n",
      "[2020-09-27 10:37:44,426] \n",
      "12/300 * Epoch 12 (_base): lr=0.0005 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): loss=0.2669\n",
      "12/300 * Epoch 12 (valid): loss=0.2679\n",
      "[2020-09-27 10:37:44,426] \n",
      "12/300 * Epoch 12 (_base): lr=0.0005 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): loss=0.2669\n",
      "12/300 * Epoch 12 (valid): loss=0.2679\n",
      "[2020-09-27 10:37:44,426] \n",
      "12/300 * Epoch 12 (_base): lr=0.0005 | momentum=0.9000\n",
      "12/300 * Epoch 12 (train): loss=0.2669\n",
      "12/300 * Epoch 12 (valid): loss=0.2679\n",
      "[2020-09-27 10:38:11,371] \n",
      "13/300 * Epoch 13 (_base): lr=0.0005 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): loss=0.2622\n",
      "13/300 * Epoch 13 (valid): loss=0.2610\n",
      "[2020-09-27 10:38:11,371] \n",
      "13/300 * Epoch 13 (_base): lr=0.0005 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): loss=0.2622\n",
      "13/300 * Epoch 13 (valid): loss=0.2610\n",
      "[2020-09-27 10:38:11,371] \n",
      "13/300 * Epoch 13 (_base): lr=0.0005 | momentum=0.9000\n",
      "13/300 * Epoch 13 (train): loss=0.2622\n",
      "13/300 * Epoch 13 (valid): loss=0.2610\n",
      "[2020-09-27 10:38:38,077] \n",
      "14/300 * Epoch 14 (_base): lr=0.0005 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): loss=0.2593\n",
      "14/300 * Epoch 14 (valid): loss=0.2655\n",
      "[2020-09-27 10:38:38,077] \n",
      "14/300 * Epoch 14 (_base): lr=0.0005 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): loss=0.2593\n",
      "14/300 * Epoch 14 (valid): loss=0.2655\n",
      "[2020-09-27 10:38:38,077] \n",
      "14/300 * Epoch 14 (_base): lr=0.0005 | momentum=0.9000\n",
      "14/300 * Epoch 14 (train): loss=0.2593\n",
      "14/300 * Epoch 14 (valid): loss=0.2655\n",
      "[2020-09-27 10:39:04,953] \n",
      "15/300 * Epoch 15 (_base): lr=0.0005 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): loss=0.2579\n",
      "15/300 * Epoch 15 (valid): loss=0.2588\n",
      "[2020-09-27 10:39:04,953] \n",
      "15/300 * Epoch 15 (_base): lr=0.0005 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): loss=0.2579\n",
      "15/300 * Epoch 15 (valid): loss=0.2588\n",
      "[2020-09-27 10:39:04,953] \n",
      "15/300 * Epoch 15 (_base): lr=0.0005 | momentum=0.9000\n",
      "15/300 * Epoch 15 (train): loss=0.2579\n",
      "15/300 * Epoch 15 (valid): loss=0.2588\n",
      "[2020-09-27 10:39:30,282] \n",
      "16/300 * Epoch 16 (_base): lr=0.0005 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): loss=0.2563\n",
      "16/300 * Epoch 16 (valid): loss=0.2612\n",
      "[2020-09-27 10:39:30,282] \n",
      "16/300 * Epoch 16 (_base): lr=0.0005 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): loss=0.2563\n",
      "16/300 * Epoch 16 (valid): loss=0.2612\n",
      "[2020-09-27 10:39:30,282] \n",
      "16/300 * Epoch 16 (_base): lr=0.0005 | momentum=0.9000\n",
      "16/300 * Epoch 16 (train): loss=0.2563\n",
      "16/300 * Epoch 16 (valid): loss=0.2612\n",
      "[2020-09-27 10:39:57,856] \n",
      "17/300 * Epoch 17 (_base): lr=0.0005 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): loss=0.2524\n",
      "17/300 * Epoch 17 (valid): loss=0.2610\n",
      "[2020-09-27 10:39:57,856] \n",
      "17/300 * Epoch 17 (_base): lr=0.0005 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): loss=0.2524\n",
      "17/300 * Epoch 17 (valid): loss=0.2610\n",
      "[2020-09-27 10:39:57,856] \n",
      "17/300 * Epoch 17 (_base): lr=0.0005 | momentum=0.9000\n",
      "17/300 * Epoch 17 (train): loss=0.2524\n",
      "17/300 * Epoch 17 (valid): loss=0.2610\n",
      "[2020-09-27 10:40:24,857] \n",
      "18/300 * Epoch 18 (_base): lr=0.0005 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): loss=0.2517\n",
      "18/300 * Epoch 18 (valid): loss=0.2570\n",
      "[2020-09-27 10:40:24,857] \n",
      "18/300 * Epoch 18 (_base): lr=0.0005 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): loss=0.2517\n",
      "18/300 * Epoch 18 (valid): loss=0.2570\n",
      "[2020-09-27 10:40:24,857] \n",
      "18/300 * Epoch 18 (_base): lr=0.0005 | momentum=0.9000\n",
      "18/300 * Epoch 18 (train): loss=0.2517\n",
      "18/300 * Epoch 18 (valid): loss=0.2570\n",
      "[2020-09-27 10:40:50,711] \n",
      "19/300 * Epoch 19 (_base): lr=0.0005 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): loss=0.2505\n",
      "19/300 * Epoch 19 (valid): loss=0.2617\n",
      "[2020-09-27 10:40:50,711] \n",
      "19/300 * Epoch 19 (_base): lr=0.0005 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): loss=0.2505\n",
      "19/300 * Epoch 19 (valid): loss=0.2617\n",
      "[2020-09-27 10:40:50,711] \n",
      "19/300 * Epoch 19 (_base): lr=0.0005 | momentum=0.9000\n",
      "19/300 * Epoch 19 (train): loss=0.2505\n",
      "19/300 * Epoch 19 (valid): loss=0.2617\n",
      "[2020-09-27 10:41:17,572] \n",
      "20/300 * Epoch 20 (_base): lr=0.0005 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): loss=0.2489\n",
      "20/300 * Epoch 20 (valid): loss=0.2584\n",
      "[2020-09-27 10:41:17,572] \n",
      "20/300 * Epoch 20 (_base): lr=0.0005 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): loss=0.2489\n",
      "20/300 * Epoch 20 (valid): loss=0.2584\n",
      "[2020-09-27 10:41:17,572] \n",
      "20/300 * Epoch 20 (_base): lr=0.0005 | momentum=0.9000\n",
      "20/300 * Epoch 20 (train): loss=0.2489\n",
      "20/300 * Epoch 20 (valid): loss=0.2584\n",
      "[2020-09-27 10:41:44,127] \n",
      "21/300 * Epoch 21 (_base): lr=0.0005 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): loss=0.2476\n",
      "21/300 * Epoch 21 (valid): loss=0.2543\n",
      "[2020-09-27 10:41:44,127] \n",
      "21/300 * Epoch 21 (_base): lr=0.0005 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): loss=0.2476\n",
      "21/300 * Epoch 21 (valid): loss=0.2543\n",
      "[2020-09-27 10:41:44,127] \n",
      "21/300 * Epoch 21 (_base): lr=0.0005 | momentum=0.9000\n",
      "21/300 * Epoch 21 (train): loss=0.2476\n",
      "21/300 * Epoch 21 (valid): loss=0.2543\n",
      "[2020-09-27 10:42:10,974] \n",
      "22/300 * Epoch 22 (_base): lr=0.0005 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): loss=0.2451\n",
      "22/300 * Epoch 22 (valid): loss=0.2542\n",
      "[2020-09-27 10:42:10,974] \n",
      "22/300 * Epoch 22 (_base): lr=0.0005 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): loss=0.2451\n",
      "22/300 * Epoch 22 (valid): loss=0.2542\n",
      "[2020-09-27 10:42:10,974] \n",
      "22/300 * Epoch 22 (_base): lr=0.0005 | momentum=0.9000\n",
      "22/300 * Epoch 22 (train): loss=0.2451\n",
      "22/300 * Epoch 22 (valid): loss=0.2542\n",
      "[2020-09-27 10:42:36,977] \n",
      "23/300 * Epoch 23 (_base): lr=0.0005 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): loss=0.2451\n",
      "23/300 * Epoch 23 (valid): loss=0.2579\n",
      "[2020-09-27 10:42:36,977] \n",
      "23/300 * Epoch 23 (_base): lr=0.0005 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): loss=0.2451\n",
      "23/300 * Epoch 23 (valid): loss=0.2579\n",
      "[2020-09-27 10:42:36,977] \n",
      "23/300 * Epoch 23 (_base): lr=0.0005 | momentum=0.9000\n",
      "23/300 * Epoch 23 (train): loss=0.2451\n",
      "23/300 * Epoch 23 (valid): loss=0.2579\n",
      "[2020-09-27 10:43:02,711] \n",
      "24/300 * Epoch 24 (_base): lr=0.0005 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): loss=0.2417\n",
      "24/300 * Epoch 24 (valid): loss=0.2557\n",
      "[2020-09-27 10:43:02,711] \n",
      "24/300 * Epoch 24 (_base): lr=0.0005 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): loss=0.2417\n",
      "24/300 * Epoch 24 (valid): loss=0.2557\n",
      "[2020-09-27 10:43:02,711] \n",
      "24/300 * Epoch 24 (_base): lr=0.0005 | momentum=0.9000\n",
      "24/300 * Epoch 24 (train): loss=0.2417\n",
      "24/300 * Epoch 24 (valid): loss=0.2557\n",
      "[2020-09-27 10:43:30,540] \n",
      "25/300 * Epoch 25 (_base): lr=0.0005 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): loss=0.2415\n",
      "25/300 * Epoch 25 (valid): loss=0.2545\n",
      "[2020-09-27 10:43:30,540] \n",
      "25/300 * Epoch 25 (_base): lr=0.0005 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): loss=0.2415\n",
      "25/300 * Epoch 25 (valid): loss=0.2545\n",
      "[2020-09-27 10:43:30,540] \n",
      "25/300 * Epoch 25 (_base): lr=0.0005 | momentum=0.9000\n",
      "25/300 * Epoch 25 (train): loss=0.2415\n",
      "25/300 * Epoch 25 (valid): loss=0.2545\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-ab598d60d934>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-d8f3380f0516>\u001b[0m in \u001b[0;36mtrain_one_fold\u001b[0;34m(tr, vl, hparams, logger, logdir, device, embeddings)\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCMSRE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSupervisedRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     runner.train(\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mloaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtr_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mvl_dl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/dl/runner/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model, criterion, optimizer, scheduler, datasets, loaders, callbacks, logdir, resume, num_epochs, valid_loader, main_metric, minimize_metric, verbose, stage_kwargs, checkpoint_data, fp16, distributed, check, overfit, timeit, load_best_on_end, initial_seed, state_kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed_cmd_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistributed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     def infer(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/utils/scripts.py\u001b[0m in \u001b[0;36mdistributed_cmd_run\u001b[0;34m(worker_fn, distributed, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mor\u001b[0m \u001b[0mworld_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     ):\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mworker_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlocal_rank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_rank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0m_exception_handler_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 987\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_exception\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    988\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     def _batch2device(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/callbacks/exception.py\u001b[0m in \u001b[0;36mon_exception\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_exception_reraise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(self, experiment)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mcatalyst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExceptionCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_stage\u001b[0;34m(self, stage)\u001b[0m\n\u001b[1;32m    941\u001b[0m             )\n\u001b[1;32m    942\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_epoch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_epoch\u001b[0;34m(self, stage, epoch)\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_train_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 922\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    923\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_loader_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_loader\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_batch_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_batch_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_early_stop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    830\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_start\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_batch_end\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/runner.py\u001b[0m in \u001b[0;36m_run_event\u001b[0;34m(self, event)\u001b[0m\n\u001b[1;32m    778\u001b[0m         \"\"\"\n\u001b[1;32m    779\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m             \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m     def _batch2device(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/catalyst/core/callbacks/optimizer.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, runner)\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_gradient_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, _, _ = train_one_fold(tr, vl, hparams, logger=None, logdir=logdir, device=device, embeddings=torch.tensor(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10, 4])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1, 10, 4).repeat(10, 1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
