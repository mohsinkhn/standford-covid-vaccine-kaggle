{
"batch_size": 16,
"num_epochs": 1000,
"num_folds": 5,
"seed": 1234786,
"seq_emb_dim": 128,
"struct_emb_dim": 128,
"pl_emb_dim": 128,
"combined_emb_dim": 150,
"gru_dim": 512,
"rnn_type": "lstm", 
"gru_layers": 3,
"bidirectional": true,
"dropout_prob": 0.75,
"spatial_dropout": 0.5,
"target_dim": 5,
"num_features": 3,
"max_seq_pred": 68,
"lr": 5e-4,
"wd": 1e-4,
"filter_sn": true,
"add_error_noise": true,
"model_name": "PretrainedTransformer",
"conv_channels": [128, 256],
"bpp_conv_channels": [128, 256, 256],
"kernel_size": 5,
"stride": 1,
"add_bpp": true,
"use_one_hot": false,
"sig_factor": 1.0,
"run_on_single": false,
"optimizer": "adam",
"scheduler": "reducelrplateau",
"conv_drop": 0.75,
"use_codon": false,
"prob_thresh": 0.0,
"signal_to_noise": 1.0,
"use_augment": false,
"loss_func": "mcrmse",
"add_segment_info": false,
"add_entropy": true,
"use_6n": false,
"adaptive_lr": false
}
